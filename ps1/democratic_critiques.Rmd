---
title: "The Critiques of Democracy"
subtitle: "Problem Set - Empirics"
author: "Dianyi Yang <br>GV482^[Questions? Email [l.bosshart@lse.ac.uk](mailto:l.bosshart@lse.ac.uk).<br>R adaption of Stephane Wolton's STATA problem set implemented by [Felix Wortmann Callej√≥n](https://www.wortmanncallejon.de).]"
date: "`r as.character(Sys.Date())`"
output: 
  bookdown::html_document2:
    fig_caption: yes
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      message = FALSE,
	warning = FALSE,
	dpi=300)


#dirname(rstudioapi::getSourceEditorContext()$path)
setwd("D:/OneDrive - London School of Economics/Desktop/lse assignments/GV482/ps1") #change to your own directory
knitr::opts_knit$set(root.dir = "D:/OneDrive - London School of Economics/Desktop/lse assignments/GV482/ps1") #use this option if the command above does not work

rm(list=ls())

#options(repos=structure(c("https://cloud.r-project.org", #"http://www.stats.ox.ac.uk/pub/RWin" ), .Names = c("CRAN", "CRANextra")))
#devtools::install_github("benmarwick/wordcountaddin",  type = "source", dependencies = TRUE) #for the wordcount addin

need <- c('tidyverse','haven','modelsummary') # list packages
have <- need %in% rownames(installed.packages()) # checks packages you have
if(any(!have)) install.packages(need[!have]) # install missing packages
invisible(lapply(need, library, character.only=T))

data <- read_dta("demcritiques_ps_data.dta") 
data$wilson1916 <- data$wilson1916 * 100
data$wilson1912 <- data$wilson1912 * 100
data$beach <- factor(data$beach)
data$machine <- factor(data$machine)
data$attack <- factor(data$attack)
data$delta_wilson <- data$wilson1916 - data$wilson1912 
```

In the lecture, we discussed the anti-democratic critiques of democracy. One of the main aspects of the critique is that voters do not have the intellectual capacity to perform the role assigned to them in democratic settings. They are too prone to emotions and this affects their ability to evaluate politicians, elections do not provide the right incentives, democracy cannot function. A prominent paper making this claim is Achen and Bartels' (2004) "Blind retrospection: Electoral responses to drought, flu, and shark attacks," available on Moodle. In this work, the two authors investigate the electoral consequences of different 'acts of God:' drought and wet spells, flu deaths, and shark attacks.[^1] Broadly summarised, Achen and Bartels claim that these events are not under the control of incumbent and, as such, should not have an effect on office-holders' electoral chances. Obviously, they find that they do (though not always), which leads them to conclude that

[^1]: The use of the 'act of God' terminology is common to contracts to refer to random unlikely events.

> "The central fact about democracies is that the voters understand little beyond their own and their community's pains and pleasures (...). The romantic vision of thoughtful democratic participation in the common life is largely mythical. Democracy must be defended some other way, if it is to be defended at all." (pp.35-36)

There has been some debates about the validity of using drought or u deaths to evaluate voters' emotional responses to random events. One result has stuck though: the effect of shark attacks in New Jersey in July 1916 on President Wilson's vote share in the following election in November of that year.[^2] According to Achen and Bartels, the economic losses due to holiday cancellations in the summer of 1916 was blamed on Wilson, leading to the incumbent president suffering electorally. A recent study by Fowler and Hall published in the Journal of Politics in 2018 ("Do shark attacks in influence presidential elections? Reassessing a prominent finding on voter competence," also available on Moodle) has cast doubt on the validity of Achen and Bartels' shark attack findings.[^3]

[^2]: Trivia: these events serve as an inspiration for Spielberg's Jaws.

[^3]: This has led to a discussion between Fowler and Hall and Achen and Bartels, which you can read [here (for Achen and Bartels' reply to the JoP article)](https://www.journals.uchicago.edu/doi/10.1086/699245) and [here (for Fowler and Hall's reply to the reply)](https://drive.google.com/file/d/1XYvjNgJWMaRS8v-O2X7Cy72zeeeH4xSS/view).

In this problem set, we will replicate and extend Fowler and Hall's replication and extension of Achen and Bartels' shark attacks findings. Fowler and Hall's paper is very rich. They look at the effect of shark attacks on all presidential elections. They consider the effect at the county level and at the town level. We will focus on the setting closest to the original analysis by Achen and Bartels. That is, we will look at the effect of shark attacks on Wilson's electoral vote shares in the 1916 presidential election at the county level (this means 21 observations, but let's not talk about this). Before looking at the empirics, we will work with the potential outcome framework as it will help us better understand some of the results we obtain.

**Q1** We denote $Y_c(\mathord{\cdot})$ the outcome of interest (in our case Wilson's vote share in the 1916 election) in a county $c$. $Y_c(\mathord{\cdot})$ is a function of two variables $T \in \{0,1\}$, whether a shark attack happened, and $Z \in \{0,1\}$ whether the county is affected (possibly indirectly) by the attacks. The idea is to separate the counties where the attacks happened from those affected by a loss of revenues from tourism even though they did not experience an attack. We denote $\overline{Y}(T,Z)$ the average of our outcome of interest and $\alpha(T,Z)$ the proportion of counties in each group. We further assume that if $T = 1$, then $Z = 1$ (that is, places where the attacks happened experienced economic losses), so there are only three possible groups: $(T = 1,Z = 1)$, $(T = 0,Z = 1)$, and $(T = 0,Z = 0)$. Throughout, we assume that $\overline{Y}(0,0) > \overline{Y}(1,1)$ and $\overline{Y}(0,0)) \ge \overline{Y}(0,1)$.

**(a)** In this first question, we suppose that the group of counties not affected by the attacks (neither directly nor indirectly) constitute the baseline (or the control group). The other counties correspond to the affected group. Using the notation above, explain briefly why the difference in means between the baseline and the treated measures:

```{=tex}
\begin{equation}
  \tau^1 = \left( \frac{\alpha(1,1)}{\alpha(1,1)+\alpha(0,1)}\overline{Y}(1,1) + \frac{\alpha(0,1)}{\alpha(1,1) + \alpha(0,1)}\overline{Y}(0,1) \right) - \overline{Y}(0,0) (\#eq:estimand1)
\end{equation}
```
***Answer:***
$$
\begin{align*}
\tau^1&=\overline{Y}(0\text{ or }1,1)-\overline{Y}(0\text{ or }1,0) \\
      &=\left( \frac{N(0,1)\overline{Y}(0,1)+N(1,1)\overline{Y}(1,1)}{N(0,1)+N(1,1)}\right)-\left( 1\times\overline{Y}(0,0)+0\times\overline{Y}(1,0)\right) \\
      &=\left( \frac{N(0,1)}{N(0,1)+N(1,1)}\overline{Y}(0,1)+\frac{N(1,1)}{N(0,1)+N(1,1)}\overline{Y}(1,1)\right) -\overline{Y}(0,0) \\
      &=\left( \frac{\alpha(0,1)}{\alpha(0,1)+\alpha(1,1)}\overline{Y}(0,1)+\frac{\alpha(1,1)}{\alpha(0,1)+\alpha(1,1)}\overline{Y}(1,1)\right)-\overline{Y}(0,0)
\end{align*}
$$

**(b)** We now suppose that the group of counties which did not experience the attack ($T=0$) constitute the baseline (or the control group). The other counties, where $T=1$, correspond to the affected group. Using the notation above, explain briefly why the difference in means between the baseline and the treated measures:

```{=tex}
\begin{equation}
\tau^2=\overline{Y}(1,1)-\left(\frac{\alpha(0,1)}{\alpha(0,1)+\alpha(0,0)}\overline{Y}(0,1)+\frac{\alpha(0,0)}{\alpha(0,1)+\alpha(0,0)}\overline{Y}(0,0)\right) (\#eq:estimand2)
\end{equation}
```
***Answer:***
$$
\begin{align*}
\tau^2&=\overline{Y}(1,0\text{ or }1)-\overline{Y}(0,0\text{ or }1) \\&=\left( 1\times\overline{Y}(1,1)+0\times\overline{Y}(1,0) \right)-\left( \frac{N(0,0)\overline{Y}(0,0)+N(0,1)\overline{Y}(0,1)}{N(0,0)+N(0,1)}\right)\\
&=\overline{Y}(1,1)-\left( \frac{N(0,0)}{N(0,0)+N(0,1)}\overline{Y}(0,0)+\frac{N(0,1)}{N(0,0)+N(0,1)}\overline{Y}(0,1)\right)\\
&=\overline{Y}(1,1)-\left( \frac{\alpha(0,0)}{\alpha(0,0)+\alpha(0,1)}\overline{Y}(0,0)+\frac{\alpha(0,1)}{\alpha(0,0)+\alpha(0,1)}\overline{Y}(0,1)\right)
\end{align*}
$$

**(c)** Suppose that $\overline{Y}(0,1)=\overline{Y}(1,1)$, show that $\tau^1<\tau^2$ then (recall that $\overline{Y}(0,0)$ is higher than the other two averages). Provide some intuition for this result.

***Answer:***
If $\overline{Y}(0,1)=\overline{Y}(1,1)$, then
$$
\begin{align*}
\tau^1&=\left( \frac{\alpha(0,1)}{\alpha(0,1)+\alpha(1,1)}\overline{Y}(0,1)+\frac{\alpha(1,1)}{\alpha(0,1)+\alpha(1,1)}\overline{Y}(1,1)\right)-\overline{Y}(0,0)\\
&=\left( \frac{\alpha(0,1)}{\alpha(0,1)+\alpha(1,1)}\overline{Y}(1,1)+\frac{\alpha(1,1)}{\alpha(0,1)+\alpha(1,1)}\overline{Y}(1,1)\right)-\overline{Y}(0,0)\\
&=\overline{Y}(1,1)-\overline{Y}(0,0)
\end{align*}
$$
$$
\begin{align*}
\tau^2&=\overline{Y}(1,1)-\left( \frac{\alpha(0,0)}{\alpha(0,0)+\alpha(0,1)}\overline{Y}(0,0)+\frac{\alpha(0,1)}{\alpha(0,0)+\alpha(0,1)}\overline{Y}(0,1)\right)\\
&=\overline{Y}(1,1)-\left( \frac{\alpha(0,0)}{\alpha(0,0)+\alpha(0,1)}\overline{Y}(0,0)+\frac{\alpha(0,1)}{\alpha(0,0)+\alpha(0,1)}\overline{Y}(1,1)\right)\\
&=\left( 1-\frac{\alpha(0,1)}{\alpha(0,0)+\alpha(0,1)}\right)\overline{Y}(1,1)-\frac{\alpha(0,0)}{\alpha(0,0)+\alpha(0,1)}\overline{Y}(0,0)\\
&=\frac{\alpha(0,0)}{\alpha(0,0)+\alpha(0,1)}\overline{Y}(1,1)-\frac{\alpha(0,0)}{\alpha(0,0)+\alpha(0,1)}\overline{Y}(0,0)\\
&=\frac{\alpha(0,0)}{\alpha(0,0)+\alpha(0,1)}\left( \overline{Y}(1,1)-\overline{Y}(0,0)\right)\\
&=\frac{\alpha(0,0)}{\alpha(0,0)+\alpha(0,1)}\tau^1
\end{align*}
$$
Since $\overline{Y}(0,0) > \overline{Y}(1,1)$, $\tau^1=\overline{Y}(1,1)-\overline{Y}(0,0)<0$. Since $\frac{\alpha(0,0)}{\alpha(0,0)+\alpha(0,1)}<1$, $|\tau^2|=\frac{\alpha(0,0)}{\alpha(0,0)+\alpha(0,1)}\tau^1<|\tau^1|$$\tau^1<\tau^2$.

Intuition: if the spillover effect is the same as treatment effect, $\tau^1$ correctly measures the treatment effect and $\tau^2$ underestimates the magnitude of the treatment effect as it includes those that are affected by the spillover in the control group, which diminishes the treatment effect.

**(d)** Suppose that $\overline{Y}(0,1)=\overline{Y}(0,0)$, show that $\tau^1>\tau^2$ then. Provide some intuition for this result.

If $\overline{Y}(0,1)=\overline{Y}(0,0)$, then

$$
\begin{align*}
\tau^2&=\overline{Y}(1,1)-\left( \frac{\alpha(0,0)}{\alpha(0,0)+\alpha(0,1)}\overline{Y}(0,0)+\frac{\alpha(0,1)}{\alpha(0,0)+\alpha(0,1)}\overline{Y}(0,1)\right)\\
&=\overline{Y}(1,1)-\left( \frac{\alpha(0,0)}{\alpha(0,0)+\alpha(0,1)}\overline{Y}(0,0)+\frac{\alpha(0,1)}{\alpha(0,0)+\alpha(0,1)}\overline{Y}(0,0)\right)\\
&=\overline{Y}(1,1)-\overline{Y}(0,0)
\end{align*}
$$

$$
\begin{align*}
\tau^1&=\left( \frac{\alpha(0,1)}{\alpha(0,1)+\alpha(1,1)}\overline{Y}(0,1)+\frac{\alpha(1,1)}{\alpha(0,1)+\alpha(1,1)}\overline{Y}(1,1)\right)-\overline{Y}(0,0)\\
&=\left( \frac{\alpha(0,1)}{\alpha(0,1)+\alpha(0,1)}\overline{Y}(0,0)+\frac{\alpha(1,1)}{\alpha(0,1)+\alpha(1,1)}\overline{Y}(1,1)\right)-\overline{Y}(0,0)\\
&=\frac{\alpha(1,1)}{\alpha(0,1)+\alpha(1,1)}\overline{Y}(1,1)+\left( \frac{\alpha(0,1)}{\alpha(0,1)+\alpha(1,1)}-1\right)\overline{Y}(0,0)\\
&=\frac{\alpha(1,1)}{\alpha(0,1)+\alpha(1,1)}\overline{Y}(1,1)-\frac{\alpha(1,1)}{\alpha(0,1)+\alpha(1,1)}\overline{Y}(0,0)\\
&=\frac{\alpha(1,1)}{\alpha(0,1)+\alpha(1,1)}\left( \overline{Y}(1,1)-\overline{Y}(0,0)\right)\\
&=\frac{\alpha(1,1)}{\alpha(0,1)+\alpha(1,1)}\tau^2
\end{align*}
$$
Since $\overline{Y}(0,0) > \overline{Y}(1,1)$, $\tau^2=\overline{Y}(1,1)-\overline{Y}(0,0)<0$. Since $\frac{\alpha(1,1)}{\alpha(0,1)+\alpha(1,1)}<1$, $|\tau^1|=\frac{\alpha(1,1)}{\alpha(0,1)+\alpha(1,1)}\tau^2<|\tau^2|$,$\tau^1>\tau^2$.

Intuition: if there is no spillover effect, $\tau^2$ correctly measures the treatment effect and $\tau^1$ underestimates the magnitude of the treatment effect as it wrongly includes those that are affected by the spillover in the treatment group, which diminishes the treatment effect.

***Answer:***

Question 1 illustrates the difficulty of interpreting results of some events (here shark attacks) when the effect of these events is not confined to the units directly affected by it (i.e., the counties where shark attacks occurred). That is, it is difficult to interpret estimates in the presence of spillover effects. We will see that it is likely that spillover effects are present in the context we study. We now turn to the data. To do so, you need to download the dataset `demcritiques_ps_data.dta` on Moodle. When you work on the empirical part of your problem set, the best practice is to create a do file and save your command there. As this is your first empirical problem set, the questions below contain quite a bit guidance, there will be less of those as we move forward in the course.

**Q2** We first reproduce Table 1 in Achen an Bartels (2004, p. 16). To do so, regress Wilson's vote share in 1916 (`wilson1916`) on the indicator variable for beach county (`beach`), a control for machine counties (`machine`)[^4], and Wilson's vote share in 1912 (`wilson1912`). To exactly reproduce the table, notice that the county of Essex is excluded from the analysis.

[^4]: Machine counties are counties where clientelism was rife and many citizens were directed to vote in a particular way. Achen and Bartels define a county with a large number of immigrants as a machine county (Scorcese's Gangs of New York provides a useful illustration of immigrant-heavy, machine-dominated districts).

***Answer:***

```{r question-2}
q2 <- lm(wilson1916 ~ beach + machine + wilson1912, data = data, subset = county != "ESSEX")
coef_map <- c('beach1' = 'Beach County', 
              'machine1' = 'Machine County', 
              'wilson1912' = 'Wilson 1912 Vote<br>
                              (3-way fraction) ',
              'Intercept' = '(Intercept)')
msummary(q2, shape=term~model+statistic, coef_map = coef_map, gof_omit ='IC|Log',
         statistic=c("std.error","statistic"),output='gt', title='Reproduciton of Table 1 in Achen an Bartels (2004, p. 16).') |>
  gt::fmt_markdown(columns = ' ')
```

As Fowler and Hall note, Achen and Bartels make several choices when analyzing the impact of shark attacks. Achen and Bartels studies how much votes Wilson received (controlling for lagged vote share) rather than trying to explain the change in vote shares. They also define the treated group as the beach counties (4 counties) rather than the two counties where the attacks took place (2 counties). They exclude one county from the analysis (in a dataset with 21 observations). None of those are necessarily bad or good choices, but we want to be sure that they are not too impactful. In the next questions, we will investigate the consequences of these choices.

**Q3** Compare the results from Achen and Bartels' regression with the estimates from (i) the same regression, but including Essex county, (ii) a regression with the counties where the attacks occurred (`attacks`) rather than beach counties (Essex county excluded), (iii) a regression in first differences (`wilson1916-wilson1912`) with beach counties as dependent variable and Essex county excluded. What do you observe?

***Answer:***

The results in Table \@ref(tab:question-3) are not sensitive to the changes above.

<span style="color: red;">The coefficient for attack county is not significant. This points to economic concerns of shark attacks rather than security concerns.</span>

```{r question-3}
with_essex <- lm(wilson1916 ~ beach + machine + wilson1912, data = data)
attack <- lm(wilson1916 ~ attack + machine + wilson1912, data = data, subset = county != "ESSEX")
first_difference <- lm(delta_wilson ~ beach + machine, data = data, subset = county != "ESSEX")
#first_difference <- lm(delta_wilson ~ beach + machine + wilson1912, data = data, subset = county != "ESSEX")

models <- list('Original' = q2,
       'With Essex' = with_essex,
       'Attack' = attack,
       'First Differences' = first_difference)
coef_map <- c('beach1' = 'Beach County',
              'attack1' = 'Attack County',
              'machine1' = 'Machine County', 
              'wilson1912' = 'Wilson 1912 Vote<br>(3-way fraction) ',
              'Intercept' = '(Intercept)')
msummary(models, coef_map = coef_map, gof_omit ='IC|Log', escape=F,
         stars=T, title="Robustness checks on Achen and Bartels' regression.")
```

The previous question only looks at a few possible changes to the specification picked by Achen and Bartels. In the next question, we replicate Figure 1 from Hall and Fowler (2018, p.1430). Hall and Fowler look at all possible specifications: using lagged or first difference, dropping one county at the time or none, using beach counties, attack counties, or coastal counties (`coastal`) as main independent variable, controlling for machine county with Achen and Bartels' measure, an alternative measure (`mayhew`), or not at all. In total, they consider 396 specifications ($2 \times 22 \times 3 \times 3=396$). Reproducing Figure 1 requires to perform several tasks:

1.  Generate a constant variable so that we do not control for whether a county is a machine county in one specification.
2.  Generate an id for each county so that we can drop one county at a time.
3.  Create an empty data frame or matrix which will store all the relevant information from the many specifications we run, this should include the coefficient, p-value, which variable is used for machine county (if any), which county is dropped (if any), which variable is used to define the affected group, and which regression is run (controlling for lagged vote share or first difference).
4.  Create a series of three loops

-   Loop 1: loop over the definition of affected counties
-   Loop 2: loop over the counties dropped (including no county at all)
-   Loop 3: loop over the control for machine
-   In this last loop, run two regressions one with lagged vote share as control and one with first difference as dependent variable. For each regression, we need to save the relevant information

As some of these steps require relatively advanced `R` coding skills, we display the code for all steps below (the same code will also be provided in the `.Rmd` file posted with the answer keys). As you advance in your GV482 journey, you will receive less and less guidance in your empirical problem set.

```{r dummy_code}

# Step 1: create a no control variable (i.e., another constant).
data$nocontrol <- 1 
# Step 2: create a an id for each county. We also want to keep the name  of the county for future reference.

data$id <-  1:21 # Generate ids

county_names <- rbind.data.frame(subset(data, select = c(county, id)), c("NONE", 0)) # save county names

# Step 3: Create a dummy data frame where we will store all the coefficients and p-value we obtain from the loops

ests <- data.frame(est = numeric(0), 
                   se = numeric(0),
                   df = numeric(0),
                   affected = character(0),
                   county = numeric(0),
                   machine = character(0),
                   lag = numeric(0))

# Step 4: We create the loop. Loops are very useful to save coding time and to conduct more complicated tasks.

# First we loop over the different definitions of being treated
for (affected in c("beach", "attack", "coastal")) { 
  
  # Next we loop over the different county identifiers, to decide which one to drop
  for (c in c(0:21)) {
    
    # Finally, we loop over the different options of controlling for machine counties
    for (machine in c("mayhew", "machine", "nocontrol")) {
      
      # We drop (or don't iff c == 0) the county with id == c
      temp <- subset(data, id != c)
      
      # We first construct the regression specification formulas
      fml1 <- as.formula(paste0("wilson1916 ~ ",affected," + ", machine, " + wilson1912"))
      fml2 <- as.formula(paste0("delta_wilson ~ ",affected," + ", machine))
      
      # We then run the two regressions and save the coefficients, standard errors, and degrees of freedom
      mod1 <- summary(lm(fml1, data = temp))[["coefficients"]]
      df1 <- lm(fml1, data = temp)$df.residual
      
      mod2 <- summary(lm(fml2, data = temp))[["coefficients"]]
      df2 <- lm(fml2, data = temp)$df.residual
      
      # We then save these into a dummy data frame, which we then append to our main collection data frame
      
      ests <- rbind.data.frame(data.frame(est = c(mod1[2,1], mod2[2,1]), # Here we grab the two beta coefficients of interest 
                                          se = c(mod1[2,2], mod2[2,2]), # Next the standard errors
                                          df = c(df1,df2), 
                                          affected = c(affected, affected), # Then the definition of being affected
                                          county = c(c, c), # The county that was dropped
                                          machine = c(machine, machine), # The control used
                                          lag = c(0,1)), # And whether we use a first difference specification or not
                               ests)
    }
  }
}

rm(temp, affected, c, machine, mod1, mod2) # remove temp vars


# We now calculate the p-value from the information in our table. As this is good practice, I won't explain why I am doing what I am doing.
ests$t <-  ests$est/ests$se
ests$p <-  (1 - pt(abs(ests$t),ests$df))*2
```

**Q4** Plot the histograms of the coefficients and the p-values you obtained. Do not forget to have a vertical line for the coefficient and p-value from Achen and Bartels as in Fowler and Hall's figure. What do you observe?

***Answer:***

The histograms in Figures \@ref(fig:question-4a) and \@ref(fig:question-4b) show that the results from Achen and Bartels are the most extreme in the distribution of coefficients and p-values. Their coefficient is among the largest in magnitude and the p-value is among the smallest. This implies that their result is not robust and could potentially be misleading.

```{r question-4a, fig.cap="Histogram of coefficients", fig.height=4, fig.width=6}
ggplot(ests, aes(x=est))+geom_histogram()+theme_bw()+geom_vline(xintercept = get_estimates(q2)[2,2], color = "red")+labs(x = "Coefficient", y = "Count")
```

```{r question-4b, fig.cap="Histogram of p-values", fig.height=4, fig.width=6}
ggplot(ests, aes(x=p))+geom_histogram()+theme_bw()+geom_vline(xintercept = get_estimates(q2)[2,9], color = "red")+labs(x = "p-value", y = "Count")
```

The histograms in Fowler and Hall are useful, but they make it hard to really observe patterns among estimates since they separate coefficients and p-values. We now try to make sense of the data with different scatter plots.

**Q5** Create a scatter plot of all the values from the estimations with the coefficients on the x-axis and the p-values on the y-axis. Your scatter plot should identify the coefficient/p-value from Achen and Bartels. What do you observe?

***Answer:***

```{r question-5, fig.cap = "Scatter plot of coefficients and p-values.", fig.align='center'}

ggplot(ests, aes(x=est, y=p)) + geom_point() + theme_bw() + geom_vline(xintercept = get_estimates(q2)[2,2], color = "red") + geom_hline(yintercept = get_estimates(q2)[2,9], color = "red") + labs(x = "Coefficient", y = "p-value")

```

In the following question, we study the patterns we observed in the scatter plot of coefficient and p-values. To do so, we will separate the observations according to the different choices we have iterated over in our loops: (1) the specification (controlling for lagged value or first difference), (2) the variable used for machine control, (3) the county dropped, (4) the definition of the affected group.

**Q6** Display scatter plots separating p-value-coefficient pairs according to the values of the four variables listed above. That is, one scatter plot should display the pairs obtained from controlling for lagged value in one colour (and/or shape) and the pairs obtained with a first difference specification in another. Another should have pairs in different colours and/or shapes for results from (i) no machine control, (ii) Achen and Bartels' measure, (iii) Mayhew's measure. Etc. Which dimension(s) appear(s) to explain the different types of results we obtained?

```{r question-6a, fig.cap = "Coefficients and p-values by lagged value or first difference specification.", fig.align='center'}
ests$lag <- as.factor(ests$lag)
ggplot(ests, aes(x=est, y=p, color = lag)) + geom_point() + theme_bw() + geom_vline(xintercept = get_estimates(q2)[2,2], color = "red") + geom_hline(yintercept = get_estimates(q2)[2,9], color = "red") + labs(x = "Coefficient", y = "p-value", color='Legend')+scale_color_hue(labels = c("Lagged value", "First Differencing"))
```
```{r question-6b, fig.cap = "Coefficients and p-values by variable used for machine control.", fig.align='center'}
ggplot(ests, aes(x=est, y=p, color = machine)) + geom_point() + theme_bw() + geom_vline(xintercept = get_estimates(q2)[2,2], color = "red") + geom_hline(yintercept = get_estimates(q2)[2,9], color = "red") + labs(x = "Coefficient", y = "p-value", color='Machine Control')
```
```{r question-6c, fig.cap = "Coefficients and p-values by county dropped.", fig.align='center'}
county_key <- c()
county_key[county_names$id] = county_names$county
ests |>
  mutate(drop = factor(county_key[as.character(county)], levels = county_key[as.character(c(0:21))])) |>
  ggplot( aes(x=est, y=p, color = drop)) + geom_point() + theme_bw() + geom_vline(xintercept = get_estimates(q2)[2,2], color = "red") + geom_hline(yintercept = get_estimates(q2)[2,9], color = "red") + labs(x = "Coefficient", y = "p-value", color='County Dropped')
```
```{r question-6d, fig.cap = "Coefficients and p-values by independent variable.", fig.align='center'}
ggplot(ests, aes(x=est, y=p, color = affected)) + geom_point() + theme_bw() + geom_vline(xintercept = get_estimates(q2)[2,2], color = "red") + geom_hline(yintercept = get_estimates(q2)[2,9], color = "red") + labs(x = "Coefficient", y = "p-value", color='Independent Variable')
```

```{r question-6e, fig.cap = "Coefficients and p-values Specification.", fig.align='center'}
ests |>
  mutate(drop = factor(county_key[as.character(county)], levels = county_key[as.character(c(0:21))])) |>
  ggplot( aes(x=est, y=p, color = drop)) + geom_point() + theme_bw() + geom_vline(xintercept = get_estimates(q2)[2,2], color = "red") + geom_hline(yintercept = get_estimates(q2)[2,9], color = "red") + labs(x = "Coefficient", y = "p-value", color='County Dropped')+
  geom_hline(yintercept=0.05, linetype='dashed')+
  facet_grid(vars(machine), vars(affected))
```
Accrording to Figures \@ref(fig:question-6a), \@ref(fig:question-6b) and \@ref(fig:question-6c), the choice of independent variable seems to explain the different types of results we obtained - the use of attack or beach as the independent variable would yield much less significant results.

***Answer:***

**Q7** Relate your findings from ***Q6*** to those from ***Q1*** to discuss whether you agree with Achen and Bartels' choice of using Beach counties as affected counties. What does this mean for the interpretation of their findings and Fowler and Hall's critique?

***Answer:***
This means that whether Achen and Bartels' choice of using Beach counties as affected counties is justified depends on our assumption about spillover effects. If we assume no spillover effect on beach counties ($\overline{Y}(0,1)=\overline{Y}(0,0)$), using attack counties as affected counties ($\tau^2$) would be more appropriate but would yield much less significant results. This would imply that Fowler and Hall's critique is valid. If we assume spillover effects to be as high as the treatment effect on attack counties ($\overline{Y}(0,1)=\overline{Y}(1,1)$), using beach counties and even coastal counties as affected counties ($\tau^1$) would be more appropriate but would yield more significant results. This would imply that Fowler and Hall's critique is not valid.

In this case, the estimates using attack counties ($\tau^2$) are smaller in magnitude than those using beach counties ($\tau^1$). In other words, $\tau^1<\tau^2$. It is more likely that $\overline{Y}(0,1)=\overline{Y}(1,1)$, so we should use beach counties as affected counties. This means that Fowler and Hall's critique is not valid on the ground of affected variable selection. However, it should also be noted that Achen and Bartels' results are among the most extreme of the results using beach counties.
